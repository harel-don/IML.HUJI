{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S6qNJ_JSlErv"
   },
   "source": [
    "# Lab 00 - A - Data Analysis In Python - First Steps\n",
    "\n",
    "Machine learning and data analysis (that is usually also a pre-step for learning) deal with data. Thererefore we need tools to manipulate it and extract the information we want. In the Python environment there are two very useful packages for this: [`numpy`](https://numpy.org/doc/1.19/) and [`pandas`](https://pandas.pydata.org/docs/reference/index.html#api).\n",
    "\n",
    "In this lab, we will take the first steps into using these packages and see some of their functionalities. These will be needed throughout the course. Both packages contain many useful functionalities, of which we will introduce only a few. To find out more about the other functionalities, the documentations, **Google** and **StackOverflow** are your best friends. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Hx4v3hy-fnu9"
   },
   "outputs": [],
   "source": [
    "# Load commonly used imports (such as numpy and pandas) and several utils functions that \n",
    "# are used thoughout different labs and code examples\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "asLx3ujI09-B"
   },
   "source": [
    "# Numpy - The Basics\n",
    "\n",
    "Let us start with numpy. This package supports vector, matrix and tensor operations over numerical (but not just) data. It is very comfortable and much faster than `for` loops and classic `list` manipulations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fPwJrL1Bc84L"
   },
   "source": [
    "## Array Creation\n",
    "\n",
    "There are multiple ways to create an array. We can create it from an existing list, load it from a file or generate a new array.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wL4cbVc-pGZ9",
    "outputId": "e5e90a34-4000-4d85-8672-7559f6ecaf6d"
   },
   "outputs": [],
   "source": [
    "array_1D = np.array([6, 2, 8, 4, 5, 10, 7, 143, 9, 10])\n",
    "print(array_1D)\n",
    "print(array_1D.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gt6ZB5FG1p2d",
    "outputId": "b3f5bdbf-9547-485a-bff1-29e07aecc6aa"
   },
   "outputs": [],
   "source": [
    "array_2D = np.array(\n",
    "    [[10, 20, 30, 40], \n",
    "     [100, 200, 300, 400], \n",
    "     [1000, 2000, 3000, 4000]])\n",
    "print(array_2D)\n",
    "print(array_2D.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ICxIiGg92M7C",
    "outputId": "5c5f5333-af82-4e07-f836-202fddf7a8fa"
   },
   "outputs": [],
   "source": [
    "array_3D = np.array(\n",
    "    [[[10, 20, 30, 40], [100, 200, 300, 400], [1000, 2000, 3000, 4000]],\n",
    "    [[11, 21, 31, 41], [101, 201, 301, 401], [1001, 2001, 3001, 4001]]])\n",
    "print(array_3D)\n",
    "print(array_3D.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u8ikdeRnpupl"
   },
   "source": [
    "Using `numpy`'s functions for creating new arrays requires specifying the shape of the desired output array. This is an n-array tuple specifying the sizes of the different dimensions. \n",
    "\n",
    "*   Specifying the shape `(3)` will create a 1D array with 3 entries.\n",
    "*   Specifying the shape `(10, 3)` will create a 2D matrix with 10 rows and 3 columns.\n",
    "*   Specifying the shape `(10, 28, 28)` will create a 3D matrix (a tensor) which we can think of in the following manner: it is an object holding 10 2D matrices of size 28x28.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iZNN-w4B2vsy",
    "outputId": "5d668f56-aae6-42cc-c13c-b6cce1b0a1bd"
   },
   "outputs": [],
   "source": [
    "# Initalize arrays with built-in numpy functions\n",
    "zeros_3D = np.zeros((4, 5, 2)) # Create a 3D arrays of 0's\n",
    "ones_2D = np.ones((4, 5)) # Create a 2D arrays of 1's\n",
    "print(zeros_3D)\n",
    "print(ones_2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3ke7ltD8qt8I",
    "outputId": "9de4ca81-d090-47e7-bbad-a7cd9dea2d5f"
   },
   "outputs": [],
   "source": [
    "np.arange(50) # Create the vector [0, 1, 2, 3, 4, .. , 48, 49]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g8tf4cd4q4oE",
    "outputId": "91be65fe-ab25-455b-9fc8-8a455b07104c"
   },
   "outputs": [],
   "source": [
    "# Create a vector of random integers from 5 to 50, with shape (2, 3)\n",
    "np.random.randint(5, 50, (2, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "THE5lTeTrN4w"
   },
   "source": [
    "There are many other functions such as `np.full`, `np.eye`, `np.random.uniform`, etc. Next, let us load an existsing dataset into a numpy array. This specific dataset represents images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "id": "O3ZsPny03qmZ",
    "outputId": "3d22fab1-7cb1-4180-a1c2-a5c1528f6de5"
   },
   "outputs": [],
   "source": [
    "img_array = np.loadtxt(open(\"../datasets/MNIST_Images.csv\", \"rb\"), delimiter=\",\").reshape(-1, 28, 28)\n",
    "img_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.imshow(img_array[0]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F10jW-AO8PdQ"
   },
   "source": [
    "## Array indexing and slicing\n",
    "\n",
    "A great strength of `numpy` is the ease in subsetting an array to retrieve only specific parts of it. We do so by indexing and slicing the arrays. For 1D arrays these operations are very similar to those over lists.  For arrays of higher dimensions, we use a comma to separate the slicing of each dimension. For example, accessing an element in the array `arr` in the first row and second column is done by: `arr[0, 1]` (recall indexing in python begins from zero). To select only the second column, over all rows write: `arr[:, 2]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KZJfKZ-_67Yk"
   },
   "outputs": [],
   "source": [
    "array_1D = np.array([10, 11, 12, 13, 14, 15, 16])\n",
    "# Select 1st element\n",
    "print(\"Select 1st element\") \n",
    "print(array_1D[1])\n",
    "\n",
    "# Select all the elements from 1st to 4th element\n",
    "print(\"\\nSelect all the elements from 1st to 4th element\") \n",
    "print(array_1D[1:5])\n",
    "\n",
    "# Select elements [1, 4]\n",
    "print(\"\\nSelect elements [1, 4]\")\n",
    "print(array_1D[[1, 4]])\n",
    "\n",
    "\n",
    "array_2D = np.array([[1, 2, 3, 4],\n",
    "                     [5, 6, 7, 8],\n",
    "                     [9, 10, 11, 12],\n",
    "                     [13, 14, 15, 16],\n",
    "                     [17, 18, 19, 20]])\n",
    "# Select 1st row, 2nd column  \n",
    "print(array_2D[1, 2])\n",
    "\n",
    "\n",
    "randint_2D = np.random.randint(5, 50, (10, 20))\n",
    "print(\"\\nPrint random array\")\n",
    "print(randint_2D)\n",
    "\n",
    "# Select from 3rd row to 5th, all the columns\n",
    "print(\"\\nSelect from 3rd row to 5th, all the columns\")\n",
    "print(randint_2D[2:5, :])\n",
    "\n",
    "# Select from 3rd row to 5th, columns 1 and 2\n",
    "print(\"\\nSelect from 3rd row to 5th, columns 1 and 2\")\n",
    "print(randint_2D[2:5, 1:3])\n",
    "\n",
    "# Select from 3d row to 5th, columns 3, 5, 6, and  11\n",
    "print(\"\\nSelect from 3rd row to 5th, columns 3, 5, 6, and  11\")\n",
    "print(randint_2D[2:5, [3, 5, 6, 11]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kn4PwoBerrJl"
   },
   "source": [
    "## Matrix Operations\n",
    "Another strength of the `numpy` package is that all matrix operations you can think of (and even more) are already implemented. For example, element-wise addition of scalar, multiplication, powering up a matrix, log-transformations and much more.\n",
    "\n",
    "As `numpy` overloads the different mathematical operators, it is easy to write mathematical expressions over 2 (or more) vectors/matrices, such as summing or multiplying and also comparing their elements.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N4OXpnPKiLbg",
    "outputId": "9d066e26-47b4-4db3-971d-5e3c4ae6a1d0"
   },
   "outputs": [],
   "source": [
    "# Operations on 1 matrix\n",
    "A = np.arange(1, 33).reshape(4, 8) # Create an array of numbers from 1 ot 32, and then make a 2d array of 4 rows to 8 columns\n",
    "print(A)\n",
    "\n",
    "print(\"\\n\\nA + 1:\")\n",
    "print(A + 1)\n",
    "print(\"\\n2 * A:\")\n",
    "print(2 * A)\n",
    "print(\"\\nA*A*A:\")\n",
    "print(np.power(A, 3))\n",
    "print(\"\\nlog(A):\")\n",
    "print(np.log(A))\n",
    "print(\"\\nA Transpose:\")\n",
    "print(A.transpose) # also np.transpose(A) and A.T are valid syntaxes\n",
    "print(\"\\n A > 10:\")\n",
    "print(A > 10)\n",
    "\n",
    "# Operations on 2 matrices\n",
    "A = np.arange(6).reshape([2, 3])\n",
    "B = np.random.randint(1, 10, (2, 3))\n",
    "print(\"A\")\n",
    "print(A)\n",
    "print(\"\\n\\nB\")\n",
    "print(B)\n",
    "\n",
    "print(\"\\nA+B:\")\n",
    "print(A + B) # Equivalent to np.add(a_array, b_array)\n",
    "print(\"\\n A * B (element-wise multiplication):\")\n",
    "print(np.multiply(A, B))\n",
    "print(\"\\n AB (matrix multiplication):\")\n",
    "print(A @ B.T) # Equivalent to np.dot(a_array, b_array)\n",
    "\n",
    "print(\"\\nA > B\")\n",
    "print(A > B)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WBGJkM0PvWPC"
   },
   "source": [
    "For many `numpy` operations we can specify the `axis` over which to perform the operation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gXznlk6aiNP3",
    "outputId": "09591fed-8ec1-44b6-e98e-af7ca2e0824e"
   },
   "outputs": [],
   "source": [
    "# Concatenate matrices\n",
    "print(\"\\nConcatenate 2 arrays by the rows:\")\n",
    "print(np.concatenate((A, B), axis = 0)) # Concatenate rows - look at the shape\n",
    "print(\"\\nConcatenate 2 arrays by the columns:\")\n",
    "print(np.concatenate((A, B), axis = 1)) # Concatenate columns - look at the shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o4O_Kvftueqx"
   },
   "source": [
    "##  Basic Statistics\n",
    "\n",
    "You can easily calculate a lot of basic statistics from an array, such as the sum, mean, variance, maximum, argmax, etc. All of these can be retrieved either over the entire array or over rows/columns.\n",
    "\n",
    "For each of these functions, you can get the statistic for: \n",
    "- the whole array: `np.stat(arr)`\n",
    "- by row: `np.stat(arr, axis = 1)`\n",
    "- by column: `np.stat(arr, axis = 0)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2JhB4W8F_gdp"
   },
   "outputs": [],
   "source": [
    "# Basic statistics of a matrix\n",
    "A = np.arange(6).reshape([2, 3])\n",
    "print(\"A\")\n",
    "print(A)\n",
    "\n",
    "print(\"\\n\\nSum of the array\")\n",
    "print(np.sum(A)) # Sum all the matrix (return a scalar)\n",
    "print(\"\\nSum of the array by column\")\n",
    "print(np.sum(A, axis = 0)) # Sum by column (return a vector)\n",
    "print(\"\\nSum of the array by row\")\n",
    "print(np.sum(A, axis = 1)) # Sum by row (return a vector)\n",
    "\n",
    "print(\"\\nMax of each row\")\n",
    "print(np.max(A, axis = 1)) # Max by column (return a vector)\n",
    "\n",
    "print(\"\\nMax of each column\")\n",
    "print(np.max(A, axis = 0)) # Max by row (return a vector)\n",
    "\n",
    "print(\"\\nAverage of all the array\")\n",
    "print(np.mean(A))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qfF-hmlYw2fL"
   },
   "source": [
    "## Sampling From Distributions\n",
    "\n",
    "`numpy` provides a broad set of distributions to sample from. We will cover this in more depth in lab 2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y2HOVVWZw1vo",
    "outputId": "131b66b9-cb51-4c99-cfb9-be294c1cdf18"
   },
   "outputs": [],
   "source": [
    "A = np.random.randint(1, 15, size = 20)\n",
    "print(\"A\")\n",
    "print(A)\n",
    "\n",
    "print(\"\\n\\nThe values that appear in the array\")\n",
    "print(np.unique(A))\n",
    "print(\"\\nHow many values are between [0, 5), [5, 10), [10, 15]\")\n",
    "np.histogram(A, bins = [0, 5, 10, 15])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BOzh7VvbzFcJ"
   },
   "source": [
    "## Linear Algebra\n",
    "One of the most important mathematical fields in machine learning is linear algebra. You can perform many of these operations using `numpy`. You can calculate the eigenvectors of a matrix, or its inverse, the rank of the matrix and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "57F3_BlBR-R3",
    "outputId": "a5c64b69-da33-451b-f54d-940f46c40cc0"
   },
   "outputs": [],
   "source": [
    "A = np.array([[1., 2.], [3., 4.]])\n",
    "print(\"A\")\n",
    "print(A)\n",
    "print(\"\\n\\nInverse of A\")\n",
    "print(np.linalg.inv(A))\n",
    "\n",
    "B = np.diag((1, 2, 3))\n",
    "print(\"\\n\\nB\")\n",
    "print(B)\n",
    "\n",
    "eigvalues, eigvectors = np.linalg.eig(B)\n",
    "print(\"\\neigenvalues, eigenvectors\")\n",
    "print(eigvalues, eigvectors)\n",
    "\n",
    "print(\"\\nRank of the matrix\")\n",
    "print(np.linalg.matrix_rank(B))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7mLWs10U0dxW"
   },
   "source": [
    "## Reshaping\n",
    "\n",
    "You can change the shape of your array, with transpose, flattening, reshape, \n",
    "adding a new axis (see `np.newaxis`)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qImJs4njAm43",
    "outputId": "3e70fefb-41fa-4c1c-d40e-1e1bb68e2590"
   },
   "outputs": [],
   "source": [
    "B = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "\n",
    "print(\"\\n\\nB\")\n",
    "print(B)\n",
    "\n",
    "print(\"\\nFlatten matrix\")\n",
    "print(np.ravel(B))\n",
    "\n",
    "\n",
    "print(\"\\nTranspose matrix\")\n",
    "print(B.transpose())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OwjDVpmk1Obt"
   },
   "source": [
    "## Sorting\n",
    "\n",
    "You can sort the matrix by row or by column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F7oe-5W4Vf2C"
   },
   "outputs": [],
   "source": [
    "B = np.array([[3, 6, 1, 4, 10], [5, 1, 8, 3, 65]])\n",
    "\n",
    "print(\"B\")\n",
    "print(B)\n",
    "\n",
    "print(\"\\n\\nSort by row\")\n",
    "print(np.sort(B, axis = 1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TCsGskFR14ff"
   },
   "source": [
    "## Indexing By Condition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YSIflm-x13uf",
    "outputId": "6790bea5-8076-416c-a327-68ec2ad1c882"
   },
   "outputs": [],
   "source": [
    "A = np.random.randint(1, 30, (5, 4))\n",
    "print(\"A\")\n",
    "print(A)\n",
    "\n",
    "print(\"\\nGet the numbers that are greater than 5:\")\n",
    "print(A[A > 5])\n",
    "\n",
    "print(\"\\nGet the numbers that are divisible by 4:\")\n",
    "print(np.extract(np.mod(A, 4)==0, A))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uZHrvwPc3xHl"
   },
   "source": [
    "## Let's practice!\n",
    "\n",
    "To get you a bit more accustomed to `numpy` you are encouraged to solve the following challenges. If you choose to not solve the following challenges, be sure to understand the solutions. Do not use loops or list comprehensions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a7IjEOuKwxbp"
   },
   "source": [
    "\n",
    "Write a program to create a `7x10` matrix that has `0` and `1` staggered:\n",
    "```\n",
    "# 0 1 0 1 0 1 0\n",
    "# 1 0 1 0 1 0 1\n",
    "# 0 1 0 1 0 1 0\n",
    "# 1 0 1 0 1 0 1\n",
    "```\n",
    "Hint: use slice operations on different axes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y_rAGqr2eknl"
   },
   "outputs": [],
   "source": [
    "staggered = np.zeros((7, 10))\n",
    "staggered[::2, 1::2] = 1\n",
    "staggered[1::2, ::2] = 1\n",
    "\n",
    "print(staggered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sQdwsu47y0_u"
   },
   "source": [
    "Calculate the volume of a cylinder with the following diameters and lengths:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bNPOP0jU2On0"
   },
   "outputs": [],
   "source": [
    "diameters = np.array([1, 3, 5, 2, 4])\n",
    "lengths = np.array([10, 20, 3, 10, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C23xh9uX6Sbj"
   },
   "outputs": [],
   "source": [
    "print(np.array(np.power(diameters/2, 2)*lengths*np.pi))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o2RXomvKz1E2"
   },
   "source": [
    "Write a function that receives 2 vectors and returns their cartesian product:\n",
    "```\n",
    "def create_cartesian_product(vec1, vec2):\n",
    "  pass\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sqo0fuvPmlsM"
   },
   "outputs": [],
   "source": [
    "def cartesian_product(vec1, vec2):\n",
    "    # np.repeat([1, 2, 3], 4) -> [1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3]\n",
    "    # np.tile([1, 2, 3], 4)   -> [1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3]\n",
    "    return np.transpose(np.array([np.repeat(vec1, len(vec2)), np.tile(vec2, len(vec1))]))\n",
    "\n",
    "print(cartesian_product([1, 2, 3], [4, 5, 6, 7]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7fmVsBdq04UL"
   },
   "source": [
    "Given an array `a` and a number `n`, find the closest number to `n` in `a`:\n",
    "```\n",
    "def find_closest(a, n):\n",
    "  pass\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8dipzX5I8AE-"
   },
   "outputs": [],
   "source": [
    "def find_closest(a, n):\n",
    "  a = np.array(a)\n",
    "  return a[np.argmin(np.abs(a - n))]\n",
    "                     \n",
    "print(find_closest([1, 24, 12, 13, 14], 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J_PKVyGO2dov"
   },
   "source": [
    "Check if the sudoku grid is valid:\n",
    "*   Check that each row contains all the numbers from 1 to 9\n",
    "*   Check that each column contains all the numbers from 1 to 9\n",
    "*   Check that each of the 9 non-overlapping `3x3` blocks composing grid contain 1 to 9\n",
    "\n",
    "You can assume it contains only integers and that the shape of the array is `9x9`\n",
    "```\n",
    "def check_sudoku(grid):\n",
    "  pass\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gZ5WPLiagvSI"
   },
   "outputs": [],
   "source": [
    "def is_1_to_9(array_):\n",
    "  # Return True if the array contains all the numbers from 1 to 9, False otherwise\n",
    "    return np.all(np.sort(array_, axis = None) == np.arange(1, 10))\n",
    "\n",
    "def check_sudoku(grid):\n",
    "    def check_block(coords_block):\n",
    "        return is_1_to_9(grid[coords_block[0]*3 : coords_block[0]*3+3, \n",
    "                              coords_block[1]*3 : coords_block[1]*3+3])\n",
    "\n",
    "    grid = np.array(grid)\n",
    "\n",
    "    # Check that the grid contains only 1 to 9\n",
    "    if (not is_1_to_9(np.unique(grid))):\n",
    "        return False\n",
    "\n",
    "    # Check that each line/column contains 1 to 9:\n",
    "    # Sort each column. We expect it to be\n",
    "    # [[1, 1, 1, 1, 1, 1, 1, 1, 1], [2, 2, 2, 2, 2, 2, 2, 2] ... [9, 9, 9, 9, 9, 9, 9, 9, 9]]\n",
    "    # Thus we expect the sums of the rows: 1*9, 2*9....\n",
    "    if  np.any(np.sum(np.sort(grid, axis = 0), axis = 1) != np.arange(1, 10)*9):\n",
    "        return False\n",
    "\n",
    "    # Make the same for the columns\n",
    "    if np.any(np.sum(np.sort(grid.transpose(), axis = 0), axis = 1) != np.arange(1, 10)*9):\n",
    "        return False\n",
    "\n",
    "\n",
    "    # 0,0 0,0 0,0    0,1 0,1 0,1    0,2 0,2 0,2\n",
    "    # 0,0 0,0 0,0    0,1 0,1 0,1    0,2 0,2 0,2\n",
    "    # 0,0 0,0 0,0    0,1 0,1 0,1    0,2 0,2 0,2\n",
    "    #\n",
    "    #\n",
    "    # 1,0 1,0 1,0    1,1 1,1 1,1    1,2 1,2 1,2\n",
    "    # 1,0 1,0 1,0    1,1 1,1 1,1    1,2 1,2 1,2\n",
    "    # 1,0 1,0 1,0    1,1 1,1 1,1    1,2 1,2 1,2\n",
    "    #\n",
    "    #\n",
    "    # 2,0 2,0 2,0    2,1 2,1 2,1    2,2 2,2 2,2\n",
    "    # 2,0 2,0 2,0    2,1 2,1 2,1    2,2 2,2 2,2\n",
    "    # 2,0 2,0 2,0    2,1 2,1 2,1    2,2 2,2 2,2\n",
    "\n",
    "\n",
    "    # For each block of 9, check if it contains all the numbers 1 to 9\n",
    "    blocks_are_valid = np.apply_along_axis(check_block, 1, cartesian_product([0, 1, 2], [0, 1, 2]))\n",
    "    return np.all(blocks_are_valid)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wmF3gn_pmP5X"
   },
   "source": [
    "Given a matrix, check if some row is a scalar multplication of another\n",
    "```\n",
    "def check_dependencies(matrix_):\n",
    "  pass\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IOxhEqkmhsRS"
   },
   "outputs": [],
   "source": [
    "def check_dependencies(matrix_):\n",
    "    def rows_are_dependent(indices):\n",
    "        if indices[0] == indices[1]:\n",
    "            return False\n",
    "        return np.unique(matrix_[indices[0],] / matrix_[indices[1],]).shape[0] == 1\n",
    "\n",
    "    return np.any(np.apply_along_axis(rows_are_dependent, 1,\n",
    "                                      cartesian_product(np.arange(matrix_.shape[0]), np.arange(matrix_.shape[0]))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dwL7kvvTkkxb"
   },
   "source": [
    "Write a function that gets a 1D array and check if there is no local extrema point in addition to the global one.\n",
    "```\n",
    "def have_an_extrema(array):\n",
    "  pass\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jg12aIuikhh3"
   },
   "outputs": [],
   "source": [
    "def have_a_maxima(array):\n",
    "    argmax_arr = np.argmax(array[1:-1]) + 1\n",
    "    before_max_neg = np.all(array[:argmax_arr - 1] - array[1:argmax_arr] < 0)\n",
    "    after_max_neg = np.all(array[argmax_arr:-1] - array[argmax_arr + 1:] > 0)\n",
    "    return before_max_neg and after_max_neg\n",
    "\n",
    "def have_an_extrema(array):\n",
    "    # Check if it is a monotonic series\n",
    "    if np.unique(array[:-1] - array[1:]).shape[0] == 1: return True\n",
    "\n",
    "    # If there is a minimum, we can look for a maximum in the negated array\n",
    "    return have_a_maxima(array) or have_a_maxima(-array)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cf0Y2F8SlK6W"
   },
   "source": [
    "Note that instead of `array[:argmax_arr - 1] - array[1:argmax_arr]`, you could use the `np.diff` function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m1S1Z7cE0E_l"
   },
   "source": [
    "# Pandas\n",
    "Until now, we have only looked at numerical data. But in real-world problems, we also have textual and categorical data. To manipulate this type of data, we will use the `pandas` library. One of the basic data structures of `pandas` is called a `DataFrame`. Generally, in a `DataFrame`, each row is a different sample and each column is a feature.\n",
    "\n",
    "For example, each row can represent a student, with columns of the ID, birthday, and gender of the student. \n",
    "\n",
    "`pandas` has a lot of possibilities of which we are going to introduce a very small subset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1JGYcSz82Viq"
   },
   "source": [
    "## Array Creation\n",
    "\n",
    "In addition to creating an array from lists or randomly generated data frames, we are going to use an existing dataset of house prices (you will get back to this dataset in excercise 2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8pjllLVn1qGW"
   },
   "outputs": [],
   "source": [
    "# Load https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data?select=train.csv\n",
    "df = pd.read_csv('../datasets/house_train.csv', index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LZZwdRpn6FIf"
   },
   "outputs": [],
   "source": [
    "print(\"\\nRows Names\")\n",
    "print(df.index)\n",
    "print(\"\\nColumns Names\")\n",
    "print(df.columns)\n",
    "print(\"\\nDf train shape\")\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ECFka5mE49Qo"
   },
   "source": [
    "## Indexing And Slicing\n",
    "Just like when using `numpy` you can select a subset of rows and columns. You can do it using indices or using names of the rows and columns. You can easily add a new column based on existing ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "svkkCAff6sYZ"
   },
   "outputs": [],
   "source": [
    "print(\"\\ndf[['GrLivArea', 'SalePrice', 'BedroomAbvGr']]\")\n",
    "print(df[['GrLivArea', 'SalePrice', 'BedroomAbvGr']]) # Select  GrLivArea columns SalePrice BedroomAbvGr\n",
    "\n",
    "print(\"\\ndf.loc[3:10,['GrLivArea', 'SalePrice', 'BedroomAbvGr'] ]\")\n",
    "print(df.loc[3:10,['GrLivArea', 'SalePrice', 'BedroomAbvGr'] ])\n",
    "\n",
    "print(\"\\ndf.iloc[[3, 4, 5]]\")\n",
    "print(df.iloc[[3, 4, 5]])\n",
    "print(\"\\ndf.iloc[3:10,[6, 7, 8]]\")\n",
    "print(df.iloc[3:10,[6, 7, 8]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qkqshRV-No7E"
   },
   "outputs": [],
   "source": [
    "individual_df = pd.DataFrame(np.array([np.random.randint(2000000, 3000000,50), np.random.uniform(1.50, 1.70, size = 50), np.random.uniform(45, 90, size = 50)]).transpose(), columns=['ID','Height','Weight'])\n",
    "\n",
    "individual_df[\"BMI\"] = individual_df[\"Weight\"] / individual_df[\"Height\"].pow(2)\n",
    "print(\"\\nIndividual DF\")\n",
    "print(individual_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eyo4hxsp5TKm"
   },
   "source": [
    "# Basic Statistics\n",
    "`pandas` provides different statistical functions over `DataFrame`s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ho-eBIBt9FQI"
   },
   "outputs": [],
   "source": [
    "print(\"\\nMedian of the SalePrice column\")\n",
    "print(df.SalePrice.median())\n",
    "\n",
    "print(\"\\nSelecting rows by condition\")\n",
    "median_price = df.SalePrice.median()\n",
    "print(df[df.SalePrice > median_price].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q8lEIqi8CDNk"
   },
   "source": [
    "## Group-by\n",
    "\n",
    "When working with data that contains also a categorical feature, we are often interested in performing some kind of calculation over all rows containing the same categorical value. For example, given a data frame of student grades for different courses, we can calculate the students' average grade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tvip9jGT-Oh8"
   },
   "outputs": [],
   "source": [
    "students_df = pd.DataFrame(np.array([np.random.choice([\"Zohar\", \"Shelly\", \"Omer\", \"Avi\"],50), np.random.choice([\"Linearit\", \"Intro\", \"Infi\", \"Probabilistic\"], 50), np.random.randint(80, 101, 50)]).transpose(), columns=['Name','Course','Grade'])\n",
    "students_df[\"Grade\"] = students_df[\"Grade\"].astype(int)\n",
    "\n",
    "print(\"\\n\\nStudents df\")\n",
    "print(students_df.head())\n",
    "\n",
    "print(\"\\n\\nCalculate average by student and by course\")\n",
    "print(students_df.groupby(['Name', 'Course']).mean().reset_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mEFa78RCK1rq"
   },
   "source": [
    "## Sorting\n",
    "As in `numpy` you can sort data frame based on a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HjdZsJab-Z3J"
   },
   "outputs": [],
   "source": [
    "students_df.sort_values(by='Grade').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4CjuO2e5LdLD"
   },
   "source": [
    "## Executing Functions By Columns\n",
    "\n",
    "In `pandas`, you can select columns and apply functions to them. You also can apply functions by elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kkRzYW7Jm1Ay"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randint(1, 10, (5,3)),columns=['col1','col2','col3'])\n",
    "\n",
    "print(\"\\n\\ndf\")\n",
    "print(df)\n",
    "print(\"\\nCalculate the difference between the min and the max of each column\")\n",
    "print(df.apply(lambda x: x.max() - x.min()))\n",
    "\n",
    "# Apply by element\n",
    "print(\"\\nMultiply elements by 100\")\n",
    "print(df.applymap(lambda x:x*100))\n",
    "\n",
    "print(\"\\n\\nIterate over the columns\")\n",
    "print(\"\\n-----------------------\")\n",
    "for key,value in df.iteritems():\n",
    "   print(key,value)\n",
    "\n",
    "print(\"\\n\\nIterate over the rows\")\n",
    "print(\"\\n-----------------------\")\n",
    "for row_idx,row in df.iterrows():\n",
    "   print(row_idx,row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dvuu9aP6Ib-G"
   },
   "source": [
    "## Merging Data Frames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "51qFkcXH9c7c"
   },
   "outputs": [],
   "source": [
    "# Concatenate data frames\n",
    "import pandas as pd\n",
    "\n",
    "# Create 2 data frames\n",
    "ids_df1 = pd.DataFrame({\n",
    "        'ID': ['336097897', '32109678', '25976389', '32438509', '36790307'],\n",
    "         'name': ['Amos', 'Eran', 'Sapir', 'Amichai', 'Hadar'], \n",
    "        'gender': [\"M\", \"M\", \"F\", \"M\", \"F\"]})\n",
    "\n",
    "ids_df2 = pd.DataFrame({\n",
    "        'ID': ['21370565', '34256798', '3908412', '326780578'],\n",
    "        'name': ['Matan', 'Gabriel', 'Anael', 'Liora'], \n",
    "        'gender': [\"M\", \"M\", \"F\", \"F\"]})\n",
    "\n",
    "print(\"\\n\\ndf1\")\n",
    "print(ids_df1)\n",
    "print(\"\\ndf2\")\n",
    "print(ids_df2)\n",
    "print(\"\\n\\nJoin the two dataframes along rows:\")\n",
    "concatenate_data = pd.concat([ids_df1, ids_df2])\n",
    "print(concatenate_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "birthdates_id = pd.DataFrame({\n",
    "        'ID': ['336097897', '32109678', '25976389', '32438509', '36790307', '21370565', '34256798', '3908412', '326780578'],\n",
    "        'birth_year': [1995, 1996, 1993, 1994, 1997, 1991, 1994, 1992, 1996]})\n",
    "\n",
    "print(\"\\nNow join the result_data and df_exam_data along ID:\")\n",
    "pd.merge(concatenate_data, birthdates_id, on='ID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4N-gAa7bcLp5"
   },
   "source": [
    "## Let's Practice!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HflHhEFaP5ya"
   },
   "source": [
    "Let us create a table of flight companies' flights. Each row will represent a single flight and will have 3 features: city of departure, city of destination and price. \n",
    "\n",
    "Implement a function `create_flight_df` that recieves a collection of cities and creates a dataset of randomly selected flights and a price in the range of 100-400.\n",
    "\n",
    "```\n",
    "    def create_flight_df(cities_poss, nrows = 100):\n",
    "        pass\n",
    "```\n",
    "\n",
    "The output data frame must not have more than a single record for any pair of cities. There are no flights from a city to itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "KWY63-sATsr9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "  Departure Destination Price\n0     Seoul   Guatemala   368\n1    Ottawa       Tokyo   358\n2     Seoul   Singapore   383\n3  New-York      Moscow   134\n4      Lima      Ankara   221",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Departure</th>\n      <th>Destination</th>\n      <th>Price</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Seoul</td>\n      <td>Guatemala</td>\n      <td>368</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Ottawa</td>\n      <td>Tokyo</td>\n      <td>358</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Seoul</td>\n      <td>Singapore</td>\n      <td>383</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>New-York</td>\n      <td>Moscow</td>\n      <td>134</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Lima</td>\n      <td>Ankara</td>\n      <td>221</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def create_flight_df(cities, nrows = 20):\n",
    "    df = pd.DataFrame([], columns=[\"Departure\", \"Destination\", \"Price\"])\n",
    "    \n",
    "    while df.shape[0] < nrows:\n",
    "        dep, dest = np.random.choice(cities, size=2, replace=False)\n",
    "        price = np.random.randint(100, 400)\n",
    "        \n",
    "        if not ((df[\"Departure\"] == dep) & (df[\"Destination\"] == dest)).any():\n",
    "            df = df.append({\"Departure\": dep, \"Destination\": dest, \"Price\": price}, ignore_index=True)\n",
    "    return df\n",
    "\n",
    "cities = [\"Beijing\", \"Moscow\", \"New-York\", \"Tokyo\", \"Paris\", \"Cairo\", \"Santiago\", \"Lima\", \"Kinshasa\", \"Singapore\", \n",
    "          \"New-Delhi\", \"London\", \"Ankara\", \"Nairobi\", \"Ottawa\", \"Seoul\", \"Tehran\", \"Guatemala\", \"Caracas\", \"Vienna\"]\n",
    "\n",
    "flights = create_flight_df(cities)\n",
    "flights.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ItISmB4RYpcJ"
   },
   "source": [
    "As there are pairs of cities with no direct flight between them, let us find the pairs of cities that have a single connection flight between them and calculate the total price of the flgihts. To do so merge the two data frames. This operation is often referred to as \"joining\" with the options of inner, outer, left, right and cross joining. For more about merging `pandas` data frames read the [documentation](https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html#database-style-dataframe-or-named-series-joining-merging)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "RvJjgHEkQq6g"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "  Departure_x Destination_x Price_x Departure_y Destination_y Price_y  \\\n0       Seoul     Guatemala     368   Guatemala      Kinshasa     247   \n1      Ottawa     Guatemala     246   Guatemala      Kinshasa     247   \n2      Ottawa         Tokyo     358       Tokyo       Beijing     338   \n3    Kinshasa         Tokyo     356       Tokyo       Beijing     338   \n4     Beijing          Lima     211        Lima        Ankara     221   \n\n  Total_Price  \n0         615  \n1         493  \n2         696  \n3         694  \n4         432  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Departure_x</th>\n      <th>Destination_x</th>\n      <th>Price_x</th>\n      <th>Departure_y</th>\n      <th>Destination_y</th>\n      <th>Price_y</th>\n      <th>Total_Price</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Seoul</td>\n      <td>Guatemala</td>\n      <td>368</td>\n      <td>Guatemala</td>\n      <td>Kinshasa</td>\n      <td>247</td>\n      <td>615</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Ottawa</td>\n      <td>Guatemala</td>\n      <td>246</td>\n      <td>Guatemala</td>\n      <td>Kinshasa</td>\n      <td>247</td>\n      <td>493</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Ottawa</td>\n      <td>Tokyo</td>\n      <td>358</td>\n      <td>Tokyo</td>\n      <td>Beijing</td>\n      <td>338</td>\n      <td>696</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Kinshasa</td>\n      <td>Tokyo</td>\n      <td>356</td>\n      <td>Tokyo</td>\n      <td>Beijing</td>\n      <td>338</td>\n      <td>694</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Beijing</td>\n      <td>Lima</td>\n      <td>211</td>\n      <td>Lima</td>\n      <td>Ankara</td>\n      <td>221</td>\n      <td>432</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.merge(flights, flights, left_on=[\"Destination\"], right_on=[\"Departure\"], how=\"inner\")\n",
    "df = df[df.Departure_x != df.Destination_y]\n",
    "df[\"Total_Price\"] = df[\"Price_x\"] + df[\"Price_y\"]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a data frame with all flights of no connection and single connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "    Departure Destination Price\n0       Seoul   Guatemala   368\n1      Ottawa       Tokyo   358\n2       Seoul   Singapore   383\n3    New-York      Moscow   134\n4        Lima      Ankara   221\n5     Beijing        Lima   211\n6    Santiago   New-Delhi   250\n7      Ottawa        Lima   234\n8    Kinshasa       Paris   177\n9    Kinshasa      Ottawa   157\n10      Tokyo     Beijing   338\n11      Seoul     Nairobi   163\n12       Lima      Ottawa   395\n13  New-Delhi     Caracas   395\n14    Caracas    Kinshasa   143\n15     Ottawa   Guatemala   246\n16    Nairobi     Caracas   313\n17  Guatemala    Kinshasa   247\n18    Caracas       Paris   269\n19   Kinshasa       Tokyo   356\n0       Seoul    Kinshasa   615\n1      Ottawa    Kinshasa   493\n2      Ottawa     Beijing   696\n3    Kinshasa     Beijing   694\n4     Beijing      Ankara   432\n5     Beijing      Ottawa   606\n6      Ottawa      Ankara   455\n8    Santiago     Caracas   645\n9    Kinshasa       Tokyo   515\n10   Kinshasa        Lima   391\n11   Kinshasa   Guatemala   403\n12       Lima       Tokyo   753\n14       Lima   Guatemala   641\n15      Tokyo        Lima   549\n16      Seoul     Caracas   476\n17  New-Delhi    Kinshasa   538\n18  New-Delhi       Paris   664\n19    Nairobi    Kinshasa   456\n20    Nairobi       Paris   582\n21    Caracas       Paris   320\n22    Caracas      Ottawa   300\n23    Caracas       Tokyo   499\n24  Guatemala       Paris   424\n25  Guatemala      Ottawa   404\n26  Guatemala       Tokyo   603",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Departure</th>\n      <th>Destination</th>\n      <th>Price</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Seoul</td>\n      <td>Guatemala</td>\n      <td>368</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Ottawa</td>\n      <td>Tokyo</td>\n      <td>358</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Seoul</td>\n      <td>Singapore</td>\n      <td>383</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>New-York</td>\n      <td>Moscow</td>\n      <td>134</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Lima</td>\n      <td>Ankara</td>\n      <td>221</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Beijing</td>\n      <td>Lima</td>\n      <td>211</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Santiago</td>\n      <td>New-Delhi</td>\n      <td>250</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Ottawa</td>\n      <td>Lima</td>\n      <td>234</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Kinshasa</td>\n      <td>Paris</td>\n      <td>177</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Kinshasa</td>\n      <td>Ottawa</td>\n      <td>157</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Tokyo</td>\n      <td>Beijing</td>\n      <td>338</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>Seoul</td>\n      <td>Nairobi</td>\n      <td>163</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>Lima</td>\n      <td>Ottawa</td>\n      <td>395</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>New-Delhi</td>\n      <td>Caracas</td>\n      <td>395</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>Caracas</td>\n      <td>Kinshasa</td>\n      <td>143</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>Ottawa</td>\n      <td>Guatemala</td>\n      <td>246</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>Nairobi</td>\n      <td>Caracas</td>\n      <td>313</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>Guatemala</td>\n      <td>Kinshasa</td>\n      <td>247</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>Caracas</td>\n      <td>Paris</td>\n      <td>269</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>Kinshasa</td>\n      <td>Tokyo</td>\n      <td>356</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>Seoul</td>\n      <td>Kinshasa</td>\n      <td>615</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Ottawa</td>\n      <td>Kinshasa</td>\n      <td>493</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Ottawa</td>\n      <td>Beijing</td>\n      <td>696</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Kinshasa</td>\n      <td>Beijing</td>\n      <td>694</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Beijing</td>\n      <td>Ankara</td>\n      <td>432</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Beijing</td>\n      <td>Ottawa</td>\n      <td>606</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Ottawa</td>\n      <td>Ankara</td>\n      <td>455</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Santiago</td>\n      <td>Caracas</td>\n      <td>645</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Kinshasa</td>\n      <td>Tokyo</td>\n      <td>515</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Kinshasa</td>\n      <td>Lima</td>\n      <td>391</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>Kinshasa</td>\n      <td>Guatemala</td>\n      <td>403</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>Lima</td>\n      <td>Tokyo</td>\n      <td>753</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>Lima</td>\n      <td>Guatemala</td>\n      <td>641</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>Tokyo</td>\n      <td>Lima</td>\n      <td>549</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>Seoul</td>\n      <td>Caracas</td>\n      <td>476</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>New-Delhi</td>\n      <td>Kinshasa</td>\n      <td>538</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>New-Delhi</td>\n      <td>Paris</td>\n      <td>664</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>Nairobi</td>\n      <td>Kinshasa</td>\n      <td>456</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>Nairobi</td>\n      <td>Paris</td>\n      <td>582</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>Caracas</td>\n      <td>Paris</td>\n      <td>320</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>Caracas</td>\n      <td>Ottawa</td>\n      <td>300</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>Caracas</td>\n      <td>Tokyo</td>\n      <td>499</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>Guatemala</td>\n      <td>Paris</td>\n      <td>424</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>Guatemala</td>\n      <td>Ottawa</td>\n      <td>404</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>Guatemala</td>\n      <td>Tokyo</td>\n      <td>603</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flights = flights.append(df[[\"Departure_x\", \"Destination_y\", \"Total_Price\"]]\\\n",
    "                         .rename(columns={\"Departure_x\":\"Departure\", \"Destination_y\":\"Destination\", \"Total_Price\":\"Price\"}))\n",
    "flights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "il0mLoEzhi6_"
   },
   "source": [
    "Since now we might have more than one way to flight between each pair of cities, let us find the cheapest flight option, with one connection, between two cities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "nYli93a6bMjB"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   Departure_x Destination_y  Total_Price\n0      Beijing        Ankara          432\n1      Beijing        Ottawa          606\n2      Caracas        Ottawa          300\n3      Caracas         Paris          320\n4      Caracas         Tokyo          499\n5    Guatemala        Ottawa          404\n6    Guatemala         Paris          424\n7    Guatemala         Tokyo          603\n8     Kinshasa       Beijing          694\n9     Kinshasa     Guatemala          403\n10    Kinshasa          Lima          391\n11    Kinshasa         Tokyo          515\n12        Lima     Guatemala          641\n13        Lima         Tokyo          753\n14     Nairobi      Kinshasa          456\n15     Nairobi         Paris          582\n16   New-Delhi      Kinshasa          538\n17   New-Delhi         Paris          664\n18      Ottawa        Ankara          455\n19      Ottawa       Beijing          696\n20      Ottawa      Kinshasa          493\n21    Santiago       Caracas          645\n22       Seoul       Caracas          476\n23       Seoul      Kinshasa          615\n24       Tokyo          Lima          549",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Departure_x</th>\n      <th>Destination_y</th>\n      <th>Total_Price</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Beijing</td>\n      <td>Ankara</td>\n      <td>432</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Beijing</td>\n      <td>Ottawa</td>\n      <td>606</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Caracas</td>\n      <td>Ottawa</td>\n      <td>300</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Caracas</td>\n      <td>Paris</td>\n      <td>320</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Caracas</td>\n      <td>Tokyo</td>\n      <td>499</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Guatemala</td>\n      <td>Ottawa</td>\n      <td>404</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Guatemala</td>\n      <td>Paris</td>\n      <td>424</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Guatemala</td>\n      <td>Tokyo</td>\n      <td>603</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Kinshasa</td>\n      <td>Beijing</td>\n      <td>694</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Kinshasa</td>\n      <td>Guatemala</td>\n      <td>403</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Kinshasa</td>\n      <td>Lima</td>\n      <td>391</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>Kinshasa</td>\n      <td>Tokyo</td>\n      <td>515</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>Lima</td>\n      <td>Guatemala</td>\n      <td>641</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>Lima</td>\n      <td>Tokyo</td>\n      <td>753</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>Nairobi</td>\n      <td>Kinshasa</td>\n      <td>456</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>Nairobi</td>\n      <td>Paris</td>\n      <td>582</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>New-Delhi</td>\n      <td>Kinshasa</td>\n      <td>538</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>New-Delhi</td>\n      <td>Paris</td>\n      <td>664</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>Ottawa</td>\n      <td>Ankara</td>\n      <td>455</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>Ottawa</td>\n      <td>Beijing</td>\n      <td>696</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>Ottawa</td>\n      <td>Kinshasa</td>\n      <td>493</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>Santiago</td>\n      <td>Caracas</td>\n      <td>645</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>Seoul</td>\n      <td>Caracas</td>\n      <td>476</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>Seoul</td>\n      <td>Kinshasa</td>\n      <td>615</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>Tokyo</td>\n      <td>Lima</td>\n      <td>549</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_by_group = df.groupby([\"Departure_x\", \"Destination_y\"], as_index=False)[\"Total_Price\"].min()\n",
    "min_by_group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TI2CrtB5irgn"
   },
   "source": [
    "And if we want to know on average what is the most expensive city to fly to then:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "DUdokeBWiq1V"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'Beijing'"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_by_dest = min_by_group.groupby(\"Destination_y\")[\"Total_Price\"].mean()\n",
    "expensive_city = mean_by_dest.idxmax()\n",
    "expensive_city"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "lab-backround-numpy.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "name": "conda-env-iml.env-py",
   "language": "python",
   "display_name": "Python [conda env:iml.env] *"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}